---
title: "P8105 Homework 3 Solutions"
author: Meghan Bellerose
date: October 1, 2020
output: github_document
---

```{r, message = FALSE}
library(tidyverse)
library(lubridate)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1: Instacart

First, I'll load Instacart data from the p8105 library.

```{r}
library(p8105.datasets)
data("instacart")
```

The Instacart dataset includes `r nrow(instacart)` rows and `r ncol(instacart)` columns. Observations are the level of items in order by user. There are user order variables, including user ID, order ID, order day, and order hour. There are also item variables, including name, aisle, department, and some numeric codes.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

There are `r count(distinct(instacart, aisle))` aisles. The aisles that most items are ordered from are fresh vegetables, fresh fruits, and packaged vegetables and fruits.


The following plot shows the number of items ordered in each aisle (limited to aisles with more than 1000 items ordered). 
```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


This table shows the three most popular items in the aisles: “baking ingredients”, “dog food care”, and “packaged vegetables fruits” and how many times each item is ordered. 

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```


This table shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour= mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()
```


# Problem 2: Accelerometers 

This problem includes data from an accelerometer dataset including five weeks of accelerometer data collected on a 63 year-old male with a BMI of 25 who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF).

First, I will load, tidy, and organize the data.

```{r}
accel_data = 
  read_csv("./data/accel_data.csv") %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "minute", 
    names_prefix = "activity.",
    values_to = "activity_count") %>% 
  group_by(day) %>% 
  mutate( 
    minute = as.numeric(minute),
    weekend = day,
    weekend = recode(weekend, "Monday" = "FALSE", "Tuesday" = "FALSE", "Wednesday" = "FALSE", "Thursday" = "FALSE", "Friday" = "FALSE", "Saturday" = "TRUE", "Sunday" = "TRUE"),
    weekend = as.logical(weekend)
  ) 

head(arrange(accel_data, day_id, week, day, weekend, minute, activity_count))
```

The final accelerometer dataset contains information on the day and week of activity collection, whether the data were collected on a weekend or weekday, and the activity count during each minute of the 24 hour days. Overall, the mean activity count per minute during the 5 week observation period was `r round(mean(pull(accel_data, activity_count)),1)`. The dataset has `r nrow(accel_data)` rows and `r ncol(accel_data)` columns. 

I'll now create a dataset aggregating activity counts over each day and produce a table showing the totals.

```{r, echo = FALSE}
accel_data %>% 
   mutate(
    day = factor(day, levels = c("Monday", 
    "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
    )%>% 
  group_by (day) %>%
  summarize(activity_total = sum(activity_count)) %>% 
  knitr::kable()
```

The table shows that total activity is highest on Friday and lowest on Saturday. It seems that the man typically had a higher activity day every other day of the week.

Now I'll make a plot showing the 24 hour activity time course for each day with activity minute on the x axis and activity count on the y axis.

```{r}
accel_data %>% 
  group_by(day) %>%
  ggplot(aes(x = minute, y = activity_count, color = day)) + 
    geom_smooth(se = FALSE) +
    labs(
      title = "24 hour activity time course by day",
      x = "Activity minute",
      y = "Activity count",
      caption = "Data from the accelerometer dataset"
  ) 
```

The plot shows that the man from whom accelerometer data was collected slept during the night (minutes 0-250 and 1375-1500 corresponding to 11pm-4am) and was active during the day. The  biggest spurts of activity were typically late Sunday monring and late Friday night.

# Problem 3

First, I'll load NY NOAA data from the p8105 library.

```{r}
library(p8105.datasets)
data("ny_noaa")
```

This dataset comes from the National Oceanic and Atmospheric Association (NOAA) National Climatic Data Center. It includes information on all New York State weather stations from January 1, 1981 to December 21, 2010, including the weather station id (id), date of observation, precipitation in tenths of mm (prcp), snowfall in mm (snow), snow depth in mm (snwd), maximum and minimum temperature in degrees C (tmax) (tmin). 

Prior to cleaning, the dataset had `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns. Since each station collects only a subset of the variables described, the dataset has a lot of missing data.

I will now clean and tidy the dataset. I converted snowfall, snow depth, and precipitation to inches.

```{r}
ny_noaa = ny_noaa %>% 
  mutate(date = ymd(date)) %>% 
  mutate_at(vars(date), funs(year, month, day)) %>% 
  mutate(
    snow_in = (snow * 0.0393701),
    snwd_in = (snwd * 0.0393701),
    prcp_in = (snwd * 0.393701)
  )
```

```{r}
ny_noaa %>% 
  summarize(mode = mode(snow, na.rm = TRUE))
```

The most commonly observed value for snowfall is 0, because it doesn't snow on many days in New York. 


