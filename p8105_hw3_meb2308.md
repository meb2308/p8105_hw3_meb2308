P8105 Homework 3 Solutions
================
Meghan Bellerose
October 1, 2020

``` r
library(tidyverse)
library(lubridate)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1: Instacart

First, I’ll load Instacart data from the p8105 library.

``` r
library(p8105.datasets)
data("instacart")
```

The Instacart dataset includes 1384617 rows and 15 columns. Observations
are the level of items in order by user. There are user order variables,
including user ID, order ID, order day, and order hour. There are also
item variables, including name, aisle, department, and some numeric
codes.

``` r
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

There are 134 aisles. The aisles that most items are ordered from are
fresh vegetables, fresh fruits, and packaged vegetables and fruits.

The following plot shows the number of items ordered in each aisle
(limited to aisles with more than 1000 items ordered).

``` r
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw3_meb2308_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

This table shows the three most popular items in the aisles: “baking
ingredients”, “dog food care”, and “packaged vegetables fruits” and how
many times each item is ordered.

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

This table shows the mean hour of the day at which Pink Lady Apples and
Coffee Ice Cream are ordered on each day of the week.

``` r
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour= mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

# Problem 2: Accelerometers

This problem includes data from an accelerometer dataset including five
weeks of accelerometer data collected on a 63 year-old male with a BMI
of 25 who was admitted to the Advanced Cardiac Care Center of Columbia
University Medical Center and diagnosed with congestive heart failure
(CHF).

First, I will load, tidy, and organize the data.

``` r
accel_data = 
  read_csv("./data/accel_data.csv") %>% 
  pivot_longer(
    activity.1:activity.1440,
    names_to = "minute", 
    names_prefix = "activity.",
    values_to = "activity_count") %>% 
  group_by(day) %>% 
  mutate(
    weekend = day,
    weekend = recode(weekend, "Monday" = "FALSE", "Tuesday" = "FALSE", "Wednesday" = "FALSE", "Thursday" = "FALSE", "Friday" = "FALSE", "Saturday" = "TRUE", "Sunday" = "TRUE"),
    weekend = as.logical(weekend)
  ) 
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
head(arrange(accel_data, day_id, week, day, weekend, minute, activity_count))
```

    ## # A tibble: 6 x 6
    ## # Groups:   day [1]
    ##    week day_id day    minute activity_count weekend
    ##   <dbl>  <dbl> <chr>  <chr>           <dbl> <lgl>  
    ## 1     1      1 Friday 1                88.4 FALSE  
    ## 2     1      1 Friday 10               43.0 FALSE  
    ## 3     1      1 Friday 100              38.5 FALSE  
    ## 4     1      1 Friday 1000            163   FALSE  
    ## 5     1      1 Friday 1001            127   FALSE  
    ## 6     1      1 Friday 1002            251   FALSE

The final accelerometer dataset contains information on the day and week
of activity collection, whether the data were collected on a weekend or
weekday, and the activity count during each minute of the 24 hour days.
Overall, the mean activity count per minute during the 5 week
observation period was 267. The dataset has 50400 rows and 6 columns.

I’ll now create a dataset aggregating activity counts over each day and
produce a table showing the totals.

    ##  day_id 138421 1440 154049 260617 295431 307094.244443979 319568
    ##       1      0    0      0      0      0                0      0
    ##       2      0    0      0      0      0                0      0
    ##       3      0    0      0      0      0                0      0
    ##       4      0    0      0      0      0                0      0
    ##       5      0    0      0      0      0                0      0
    ##       6      0    0      0      0      0             1440      0
    ##       7      0    0      0      0      0                0      0
    ##       8      0    0      0      0      0                0      0
    ##       9      0    0      0      0   1440                0      0
    ##      10      0    0      0      0      0                0      0
    ##      11      0    0      0      0      0                0      0
    ##      12      0    0      0      0      0                0      0
    ##      13      0    0      0      0      0                0      0
    ##      14      0    0      0      0      0                0      0
    ##      15      0    0      0      0      0                0      0
    ##      16      0    0      0      0      0                0      0
    ##      17      0    0      0      0      0                0      0
    ##      18      0    0      0      0      0                0      0
    ##      19      0    0      0      0      0                0      0
    ##      20      0    0      0      0      0                0      0
    ##      21      0    0      0      0      0                0      0
    ##      22      0    0   1440      0      0                0      0
    ##      23      0    0      0      0      0                0      0
    ##      24      0 1440      0      0      0                0      0
    ##      25      0    0      0   1440      0                0      0
    ##      26      0    0      0      0      0                0      0
    ##      27      0    0      0      0      0                0   1440
    ##      28      0    0      0      0      0                0      0
    ##      29      0    0      0      0      0                0      0
    ##      30      0    0      0      0      0                0      0
    ##      31      0 1440      0      0      0                0      0
    ##      32   1440    0      0      0      0                0      0
    ##      33      0    0      0      0      0                0      0
    ##      34      0    0      0      0      0                0      0
    ##      35      0    0      0      0      0                0      0
    ##  340115.009595833 340291 355923.644445795 367824 371230 376254 381507 382928
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0   1440      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0             1440      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##              1440      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0   1440
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0   1440      0      0      0
    ##                 0      0                0      0      0      0   1440      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0   1440                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##                 0      0                0   1440      0      0      0      0
    ##                 0      0                0      0      0      0      0      0
    ##  389080 409450 422018 423245 434460 440962 445366 467052 467420 468869 474048
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0   1440      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0   1440
    ##       0      0      0   1440      0      0      0      0      0      0      0
    ##       0      0      0      0      0   1440      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0   1440      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0   1440      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0   1440      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0   1440      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0   1440      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##    1440      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0      0      0      0      0      0
    ##       0      0      0      0      0      0   1440      0      0      0      0
    ##  480542.620789719 549658 568839 607175 620860 631105 685910 78828.06666767
    ##              1440      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0           1440
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0   1440      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0   1440      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0   1440      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0   1440              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0   1440      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0   1440      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0
    ##                 0      0      0      0      0      0      0              0

The trends are..

# Problem 3

First, I’ll load NY NOAA data from the p8105 library.

``` r
library(p8105.datasets)
data("ny_noaa")
```

This dataset comes from the National Oceanic and Atmospheric Association
(NOAA) National Climatic Data Center. It includes information on all New
York State weather stations from January 1, 1981 to December 21, 2010,
including the weather station id (id), date of observation,
precipitation in tenths of mm (prcp), snowfall in mm (snow), snow depth
in mm (snwd), maximum and minimum temperature in degrees C (tmax)
(tmin).

Prior to cleaning, the dataset had 2595176 rows and 7 columns. Since
each station collects only a subset of the variables described, the
dataset has a lot of missing data.

I will now clean and tidy the dataset.

``` r
ny_noaa = ny_noaa %>% 
  mutate(date = ymd(date)) %>% 
  mutate_at(vars(date), funs(year, month, day))
```

    ## Warning: `funs()` is deprecated as of dplyr 0.8.0.
    ## Please use a list of either functions or lambdas: 
    ## 
    ##   # Simple named list: 
    ##   list(mean = mean, median = median)
    ## 
    ##   # Auto named with `tibble::lst()`: 
    ##   tibble::lst(mean, median)
    ## 
    ##   # Using lambdas
    ##   list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))
    ## This warning is displayed once every 8 hours.
    ## Call `lifecycle::last_warnings()` to see where this warning was generated.
